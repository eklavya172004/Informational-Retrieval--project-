# -*- coding: utf-8 -*-
"""Final RAG WORKTHROUGH.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qx3KZ5spxWMoeNt8Msv_Fv1cZDHlqALK
"""

# ============================================================
# INSTALL PACKAGES
# ============================================================
!pip install sentence-transformers faiss-cpu google-generativeai rank-bm25 tabulate matplotlib

import numpy as np
import pandas as pd
import faiss
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sentence_transformers import SentenceTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from tabulate import tabulate
import google.generativeai as genai
from google.colab import files
from google.colab import userdata
from rank_bm25 import BM25Okapi
import matplotlib.pyplot as plt
import zipfile, os

# ============================================================
# NLTK SETUP
# ============================================================
nltk.download("stopwords")
stop_words = set(stopwords.words("english"))
stemmer = PorterStemmer()

# ============================================================
# CLEANING FOR IR ONLY
# ============================================================
def classic_clean(text):
    text = text.lower()
    text = re.sub(r"[^a-z0-9 ]", " ", text)
    words = [w for w in text.split() if w not in stop_words]
    words = [stemmer.stem(w) for w in words]
    return " ".join(words)

# ============================================================
# UPLOAD CORPUS ZIP
# ============================================================
# ============================================================
# LOAD CORPUS FROM GOOGLE DRIVE (NO UPLOAD)
# ============================================================
from google.colab import drive
drive.mount('/content/drive')

# Your corpus directory
CORPUS_DIR = r"/content/drive/My Drive/wikipedia_medical_corpus"

records = []
for root, dirs, files_ in os.walk(CORPUS_DIR):
    for fname in files_:
        if fname.endswith(".txt"):
            file_path = os.path.join(root, fname)

            # Try utf-8, fallback to latin-1
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    text = f.read()
            except UnicodeDecodeError:
                with open(file_path, "r", encoding="latin-1") as f:
                    text = f.read()

            records.append({
                "title": fname.replace(".txt", ""),
                "content": text
            })

df = pd.DataFrame(records)
print(f"Loaded {len(df)} documents from: {CORPUS_DIR}")


# ============================================================
# CLASSIC IR PIPELINE
# ============================================================
df["clean_classic"] = df["content"].apply(classic_clean)

tfidf = TfidfVectorizer()
tfidf_matrix = tfidf.fit_transform(df["clean_classic"])

sim_sparse = tfidf_matrix @ tfidf_matrix.T
sim_matrix = sim_sparse.toarray()
np.fill_diagonal(sim_matrix, 0)

row_sum = sim_matrix.sum(axis=1, keepdims=True)
P = sim_matrix / (row_sum + 1e-10)

# PageRank
def pagerank(P, d=0.85, it=100):
    n = P.shape[0]
    r = np.ones(n) / n
    for _ in range(it):
        r = d * P.T @ r + (1-d)/n
    return r

df["pagerank"] = pagerank(P)

# HITS
def hits(P, it=100):
    n = P.shape[0]
    h = np.ones(n)
    a = np.ones(n)
    for _ in range(it):
        a = P.T @ h
        h = P @ a
        a /= (np.linalg.norm(a)+1e-10)
        h /= (np.linalg.norm(h)+1e-10)
    return h,a

hub, auth = hits(P)
df["authority"] = auth
df["hub"] = hub

# Clustering
kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
df["cluster"] = kmeans.fit_predict(tfidf_matrix)

# ============================================================
# TF-IDF SEARCH
# ============================================================
def search_tfidf(q, k=5):
    q1 = classic_clean(q)
    q_vec = tfidf.transform([q1])
    scores = (tfidf_matrix @ q_vec.T).toarray().ravel()

    if scores.max() < 1e-4:
        return pd.DataFrame()

    idx = scores.argsort()[::-1][:k]
    out = df.iloc[idx].copy()
    out["tfidf_score"] = scores[idx]
    return out

# ============================================================
# CLASSIC IR ANSWER + GRAPH
# ============================================================
def classic_answer(query):
    res = search_tfidf(query)

    if res.empty:
        return f"No IR matches found for: {query}", None

    rows = []
    for _, r in res.iterrows():
        rows.append([
            r["title"],
            f"{r['tfidf_score']:.4f}",
            f"{r['pagerank']:.4f}",
            f"{r['authority']:.4f}",
            int(r["cluster"])
        ])

    table = tabulate(
        rows,
        headers=["Document","TF-IDF","PageRank","Authority","Cluster"],
        tablefmt="grid"
    )

    # Graph
    plt.figure(figsize=(7,5))
    plt.scatter(df["pagerank"], df["authority"], alpha=0.3)
    plt.scatter(res["pagerank"], res["authority"], c="red", s=80)

    for _, r in res.iterrows():
        plt.text(r["pagerank"], r["authority"], r["title"], fontsize=8)

    plt.xlabel("PageRank")
    plt.ylabel("Authority")
    plt.title(f"PageRank vs Authority for '{query}'")
    plt.grid(True)
    plt.show()

    return "Classic IR Results:\n\n" + table, res

# ============================================================
# RAG SETUP (RAW CORPUS ONLY)
# ============================================================
embed_model = SentenceTransformer("all-MiniLM-L6-v2")
corpus = df["content"].tolist()
titles = df["title"].tolist()

emb = embed_model.encode(corpus,show_progress_bar=False).astype("float32")
index = faiss.IndexFlatL2(emb.shape[1])
index.add(emb)

# Gemini
try:
    key = userdata.get("GEMINI_API_KEY")
except:
    key = input("Enter Gemini API key: ")

genai.configure(api_key=key)
llm = genai.GenerativeModel(
    "gemini-2.5-flash",
    generation_config={"max_output_tokens": 4096,"temperature": 0.6}
)

# ============================================================
# RETRIEVE RAW DOCS
# ============================================================
def retrieve_docs(query, k=3):
    q = embed_model.encode([query]).astype("float32")
    dist, idx = index.search(q, k)

    docs = []
    for d,i in zip(dist[0], idx[0]):
        docs.append({
            "title": titles[i],
            "content": corpus[i],
            "distance": float(d),
            "relevance": round(1/(d+1),3)
        })
    return docs

# ============================================================
# FORMATTED PROMPT
# ============================================================
def build_prompt(query, docs):
    ctx = ""
    for d in docs:
        ctx += f"\n--- DOCUMENT: {d['title']} ---\n{d['content'][:2000]}\n"

    return f"""
You are an expert medical summarizer. Use ONLY the text from the provided documents.

Rules:
- Do NOT give medical advice.
- Use only the information from the documents.
- Structure the answer with clear headings.
- At the end, list all sources.

================================================================================
üß† ANSWER FOR QUERY: {query}

### Overview
(Explain topic using only the docs.)

### Document-wise Details
For each document:

#### üìÑ <document title>
- Key points
- Symptoms
- Risk Factors
- Diagnosis
- Treatments
- Important facts

### Combined Explanation
(Summarize all documents together.)

### Sources
(List all document titles)
================================================================================

Documents:
{ctx}

Now write the answer:
"""

# ============================================================
# FORMATTED RAG ANSWER
# ============================================================
def rag_answer(query):
    docs = retrieve_docs(query)

    print("üìö Retrieved Documents:")
    for d in docs:
        print(f"  ‚Ä¢ {d['title']} (relevance: {d['relevance']})")

    prompt = build_prompt(query, docs)

    try:
        out = llm.generate_content(prompt)
        return out.text
    except Exception as e:
        return f"RAG blocked or failed: {e}"

# ============================================================
# ASK (IR + RAG)
# ============================================================
def ask(query):
    print("\n===== IR ANSWER =====\n")
    table, _ = classic_answer(query)
    print(table)

    print("\n===== RAG ANSWER =====\n")
    print(rag_answer(query))

# ============================================================
# INTERACTIVE CHAT
# ============================================================
def rag_chat():
    print("ü§ñ RAG SYSTEM READY - Ask me anything!")
    print("======================================\n")
    while True:
        q = input("‚ùì Your question: ").strip()
        if q.lower() in ["quit","exit","bye"]:
            print("Goodbye!")
            break

        print("\n===== IR ANSWER =====")
        table, _ = classic_answer(q)
        print(table)

        print("\n===== RAG ANSWER =====\n")
        print(rag_answer(q))
        print("\n--------------------------------------\n")

rag_chat()