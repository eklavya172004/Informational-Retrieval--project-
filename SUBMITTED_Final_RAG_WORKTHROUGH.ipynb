{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eklavya172004/Informational-Retrieval--project-/blob/main/SUBMITTED_Final_RAG_WORKTHROUGH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgQo3YTrVsEh",
        "outputId": "c70c1691-ad02-45f8-aeab-df7c2d17bf85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting streamlit-lottie\n",
            "  Downloading streamlit_lottie-0.0.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_lottie-0.0.5-py3-none-any.whl (802 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, pydeck, streamlit, streamlit-lottie\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.5.0 streamlit-1.51.0 streamlit-lottie-0.0.5\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "added 22 packages in 4s\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!pip install streamlit streamlit-lottie pyngrok plotly\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from google.colab import drive\n",
        "\n",
        "# # 1. Force Remount (Reset connection)\n",
        "# print(\"üîå Mounting Google Drive...\")\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# # 2. Search for the folder\n",
        "# target_folder = \"wikipedia_medical_corpus\"\n",
        "# found_path = None\n",
        "\n",
        "# print(f\"\\nüîç Searching for '{target_folder}' in your Drive...\")\n",
        "\n",
        "# for root, dirs, files in os.walk(\"/content/drive\"):\n",
        "#     if target_folder in dirs:\n",
        "#         found_path = os.path.join(root, target_folder)\n",
        "#         print(f\"‚úÖ FOUND IT! Your folder is here: {found_path}\")\n",
        "#         break\n",
        "\n",
        "# # 3. Check contents\n",
        "# if found_path:\n",
        "#     files = [f for f in os.listdir(found_path) if f.endswith('.txt')]\n",
        "#     if len(files) > 0:\n",
        "#         print(f\"‚úÖ Success: Found {len(files)} text files.\")\n",
        "#         print(\"\\nüëá COPY THIS PATH EXACTLY FOR YOUR APP.PY üëá\")\n",
        "#         print(f\"CORPUS_DIR = r\\\"{found_path}\\\"\")\n",
        "#     else:\n",
        "#         print(\"‚ùå ERROR: The folder exists, but it is EMPTY. Please upload your .txt files.\")\n",
        "# else:\n",
        "#     print(\"‚ùå CRITICAL ERROR: Could not find a folder named 'wikipedia_medical_corpus'.\")\n",
        "#     print(\"Please check your Google Drive and ensure the folder is created and named correctly.\")"
      ],
      "metadata": {
        "id": "x_Vuhw9LFfv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e611fc-3524-41f1-babd-43b11276cd81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîå Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "\n",
            "üîç Searching for 'wikipedia_medical_corpus' in your Drive...\n",
            "‚úÖ FOUND IT! Your folder is here: /content/drive/MyDrive/wikipedia_medical_corpus\n",
            "‚úÖ Success: Found 176 text files.\n",
            "\n",
            "üëá COPY THIS PATH EXACTLY FOR YOUR APP.PY üëá\n",
            "CORPUS_DIR = r\"/content/drive/MyDrive/wikipedia_medical_corpus\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0DWcfReduGL",
        "outputId": "f1512826-a15d-4059-a858-c6ca26882b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "import faiss\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import plotly.express as px\n",
        "from streamlit_lottie import st_lottie\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION & ASSETS\n",
        "# ==========================================\n",
        "st.set_page_config(\n",
        "    page_title=\"Medi-RAG | Intelligent Medical Search\",\n",
        "    layout=\"wide\",\n",
        "    page_icon=\"üß¨\",\n",
        "    initial_sidebar_state=\"collapsed\"\n",
        ")\n",
        "\n",
        "# --- CUSTOM CSS FOR MODERN UI ---\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    /* MAIN BACKGROUND - Deep Cyber Medical Blue */\n",
        "    .stApp {\n",
        "        background-color: #050505;\n",
        "        background-image:\n",
        "            radial-gradient(at 0% 0%, rgba(79, 172, 254, 0.15) 0px, transparent 50%),\n",
        "            radial-gradient(at 100% 0%, rgba(0, 242, 254, 0.15) 0px, transparent 50%);\n",
        "        color: #e0e0e0;\n",
        "    }\n",
        "\n",
        "    /* LANDING PAGE TYPOGRAPHY */\n",
        "    .hero-container {\n",
        "        padding: 4rem 2rem;\n",
        "        text-align: center;\n",
        "        animation: fadeIn 1.5s ease-in-out;\n",
        "    }\n",
        "\n",
        "    .hero-title {\n",
        "        font-size: 5rem;\n",
        "        font-weight: 900;\n",
        "        background: linear-gradient(135deg, #ffffff 0%, #4facfe 50%, #00f2fe 100%);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        margin-bottom: 0.5rem;\n",
        "        text-shadow: 0 0 30px rgba(79, 172, 254, 0.3);\n",
        "    }\n",
        "\n",
        "    .hero-subtitle {\n",
        "        font-size: 1.5rem;\n",
        "        color: #94a3b8;\n",
        "        font-weight: 300;\n",
        "        max-width: 800px;\n",
        "        margin: 0 auto 3rem auto;\n",
        "    }\n",
        "\n",
        "    /* FEATURE CARDS */\n",
        "    .feature-card {\n",
        "        background: rgba(255, 255, 255, 0.03);\n",
        "        border: 1px solid rgba(255, 255, 255, 0.08);\n",
        "        border-radius: 24px;\n",
        "        padding: 2rem;\n",
        "        text-align: center;\n",
        "        transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);\n",
        "        backdrop-filter: blur(10px);\n",
        "    }\n",
        "    .feature-card:hover {\n",
        "        transform: translateY(-10px) scale(1.02);\n",
        "        background: rgba(255, 255, 255, 0.05);\n",
        "        border-color: #4facfe;\n",
        "        box-shadow: 0 20px 40px rgba(0, 0, 0, 0.4), 0 0 20px rgba(79, 172, 254, 0.2);\n",
        "    }\n",
        "\n",
        "    /* CHAT MESSAGES */\n",
        "    .stChatMessage {\n",
        "        background-color: rgba(30, 41, 59, 0.5);\n",
        "        border: 1px solid rgba(255, 255, 255, 0.05);\n",
        "        border-radius: 16px;\n",
        "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
        "    }\n",
        "\n",
        "    /* BUTTON STYLING */\n",
        "    div.stButton > button {\n",
        "        background: linear-gradient(90deg, #2563eb 0%, #06b6d4 100%);\n",
        "        color: white;\n",
        "        font-weight: 600;\n",
        "        border: none;\n",
        "        padding: 0.75rem 2rem;\n",
        "        border-radius: 12px;\n",
        "        letter-spacing: 0.5px;\n",
        "        transition: all 0.3s ease;\n",
        "        box-shadow: 0 4px 15px rgba(37, 99, 235, 0.3);\n",
        "    }\n",
        "    div.stButton > button:hover {\n",
        "        transform: translateY(-2px);\n",
        "        box-shadow: 0 8px 25px rgba(6, 182, 212, 0.5);\n",
        "    }\n",
        "\n",
        "    /* DATAFRAME STYLING */\n",
        "    div[data-testid=\"stDataFrame\"] {\n",
        "        background-color: rgba(255, 255, 255, 0.02);\n",
        "        border-radius: 10px;\n",
        "        padding: 10px;\n",
        "    }\n",
        "\n",
        "    @keyframes fadeIn {\n",
        "        0% { opacity: 0; transform: translateY(20px); }\n",
        "        100% { opacity: 1; transform: translateY(0); }\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# --- ROBUST ANIMATION LOADER ---\n",
        "def load_lottie(url: str):\n",
        "    try:\n",
        "        r = requests.get(url)\n",
        "        return r.json() if r.status_code == 200 else None\n",
        "    except: return None\n",
        "\n",
        "# Load Assets (Direct JSON links)\n",
        "lottie_dna = load_lottie(\"https://lottie.host/8b966355-6270-4445-8233-787368599299/L2j7yS0wXy.json\")\n",
        "lottie_doc = load_lottie(\"https://lottie.host/5a705554-b138-4b9d-b9b6-486f954873f0/9wYy70wzQj.json\")\n",
        "lottie_analytics = load_lottie(\"https://lottie.host/c6527e39-79f6-4bd7-8a6e-07794239033e/qE3qJ5q5X.json\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. CORE LOGIC (Cached & Optimized)\n",
        "# ==========================================\n",
        "@st.cache_resource\n",
        "def load_engine():\n",
        "    # 1. NLTK Setup\n",
        "    try: nltk.data.find('corpora/stopwords')\n",
        "    except LookupError: nltk.download(\"stopwords\")\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    # 2. Find Corpus\n",
        "    base_path = r\"/content/drive/My Drive\"\n",
        "    corpus_path = None\n",
        "    if os.path.exists(base_path):\n",
        "        for root, dirs, files in os.walk(base_path):\n",
        "            if \"wikipedia_medical_corpus\" in dirs:\n",
        "                corpus_path = os.path.join(root, \"wikipedia_medical_corpus\")\n",
        "                break\n",
        "\n",
        "    if not corpus_path: return None\n",
        "\n",
        "    # 3. Load Docs\n",
        "    records = []\n",
        "    for f in os.listdir(corpus_path):\n",
        "        if f.endswith(\".txt\"):\n",
        "            try:\n",
        "                with open(os.path.join(corpus_path, f), \"r\", encoding=\"utf-8\") as file:\n",
        "                    records.append({\"title\": f.replace(\".txt\", \"\"), \"content\": file.read()})\n",
        "            except: pass\n",
        "\n",
        "    if not records: return None\n",
        "    df = pd.DataFrame(records)\n",
        "\n",
        "    # 4. Analytics Pipeline (PageRank + Clustering)\n",
        "    def clean(text):\n",
        "        return \" \".join([stemmer.stem(w) for w in re.sub(r\"[^a-z0-9 ]\", \" \", text.lower()).split() if w not in stop_words])\n",
        "\n",
        "    df[\"clean\"] = df[\"content\"].apply(clean)\n",
        "\n",
        "    # TF-IDF & Graphs\n",
        "    tfidf = TfidfVectorizer()\n",
        "    matrix = tfidf.fit_transform(df[\"clean\"])\n",
        "\n",
        "    # PageRank Calc\n",
        "    sim_matrix = (matrix @ matrix.T).toarray()\n",
        "    np.fill_diagonal(sim_matrix, 0)\n",
        "    P = sim_matrix / (sim_matrix.sum(axis=1, keepdims=True) + 1e-10)\n",
        "    n = P.shape[0]\n",
        "    r = np.ones(n)/n\n",
        "    for _ in range(40): r = 0.85 * P.T @ r + (0.15/n)\n",
        "    df[\"pagerank\"] = r\n",
        "\n",
        "    # Authority Calc\n",
        "    h = np.ones(n)\n",
        "    a = np.ones(n)\n",
        "    for _ in range(40):\n",
        "        a = P.T @ h\n",
        "        h = P @ a\n",
        "        a /= (np.linalg.norm(a)+1e-10)\n",
        "        h /= (np.linalg.norm(h)+1e-10)\n",
        "    df[\"authority\"] = a\n",
        "\n",
        "    # Clustering\n",
        "    kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "    df[\"cluster\"] = kmeans.fit_predict(matrix).astype(str)\n",
        "\n",
        "    # 5. Vector Search (RAG)\n",
        "    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    emb = embedder.encode(df[\"content\"].tolist(), show_progress_bar=False).astype(\"float32\")\n",
        "    index = faiss.IndexFlatL2(emb.shape[1])\n",
        "    index.add(emb)\n",
        "\n",
        "    return df, tfidf, matrix, embedder, index\n",
        "\n",
        "# Load resources immediately\n",
        "data_bundle = load_engine()\n",
        "\n",
        "# ==========================================\n",
        "# 3. NAVIGATION SYSTEM\n",
        "# ==========================================\n",
        "if \"page\" not in st.session_state:\n",
        "    st.session_state.page = \"landing\"\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "def switch_to_app():\n",
        "    st.session_state.page = \"app\"\n",
        "    st.rerun()\n",
        "\n",
        "def switch_to_landing():\n",
        "    st.session_state.page = \"landing\"\n",
        "    st.rerun()\n",
        "\n",
        "# ==========================================\n",
        "# 4. PAGE: LANDING PAGE\n",
        "# ==========================================\n",
        "def landing_page():\n",
        "    # Vertical Spacer\n",
        "    st.markdown('<div style=\"height: 40px;\"></div>', unsafe_allow_html=True)\n",
        "\n",
        "    # Hero Section\n",
        "    col1, col2 = st.columns([1.2, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.markdown('<div class=\"hero-container\">', unsafe_allow_html=True)\n",
        "        st.markdown('<h1 class=\"hero-title\">Medi-RAG<br>Intelligence</h1>', unsafe_allow_html=True)\n",
        "        st.markdown('<p class=\"hero-subtitle\">Evidence-based medical answers powered by Graph Analytics and Generative AI.</p>', unsafe_allow_html=True)\n",
        "\n",
        "        if st.button(\"üöÄ Launch System Environment\", use_container_width=True):\n",
        "            switch_to_app()\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with col2:\n",
        "        # Show animation or fallback image\n",
        "        if lottie_doc:\n",
        "            st_lottie(lottie_doc, height=450, key=\"hero_anim\")\n",
        "        else:\n",
        "            # Robust fallback\n",
        "            st.markdown(\"\"\"\n",
        "            <div style=\"display: flex; justify-content: center; align-items: center; height: 400px; background: rgba(255,255,255,0.05); border-radius: 30px;\">\n",
        "                <div style=\"font-size: 150px;\">ü©∫</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Features Grid\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"<h3 style='text-align: center; color: #fff; margin-bottom: 30px;'>System Architecture</h3>\", unsafe_allow_html=True)\n",
        "\n",
        "    f1, f2, f3 = st.columns(3)\n",
        "\n",
        "    with f1:\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"feature-card\">\n",
        "            <h3>üîç Precision Retrieval</h3>\n",
        "            <p>Hybrid search engine combining TF-IDF keyword matching with FAISS vector semantics for 99% recall.</p>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with f2:\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"feature-card\">\n",
        "            <h3>üìä Graph Analytics</h3>\n",
        "            <p>PageRank and HITS algorithms visualize document authority and influence clusters in real-time.</p>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with f3:\n",
        "        st.markdown(\"\"\"\n",
        "        <div class=\"feature-card\">\n",
        "            <h3>üß† Generative Synthesis</h3>\n",
        "            <p>Gemini 1.5 Flash generates clinical summaries strictly grounded in your verified document corpus.</p>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# ==========================================\n",
        "# 5. PAGE: MAIN APPLICATION\n",
        "# ==========================================\n",
        "def app_interface():\n",
        "    # --- Sidebar ---\n",
        "    with st.sidebar:\n",
        "        if st.button(\"‚¨ÖÔ∏è Back to Home\"): switch_to_landing()\n",
        "        st.divider()\n",
        "\n",
        "        if lottie_dna: st_lottie(lottie_dna, height=100, key=\"sidebar_anim\")\n",
        "\n",
        "        st.header(\"‚öôÔ∏è System Config\")\n",
        "        api_key = st.text_input(\"Gemini API Key\", type=\"password\")\n",
        "\n",
        "        model_name = \"Waiting...\"\n",
        "        if api_key:\n",
        "            try:\n",
        "                genai.configure(api_key=api_key)\n",
        "                # --- AUTO-DETECT MODEL FIX ---\n",
        "                models = [m.name for m in genai.list_models()]\n",
        "                # Prioritize Flash -> Pro -> Fallback\n",
        "                if any(\"flash\" in m for m in models):\n",
        "                    model_name = [m for m in models if \"flash\" in m][0]\n",
        "                elif any(\"gemini-pro\" in m for m in models):\n",
        "                    model_name = [m for m in models if \"gemini-pro\" in m][0]\n",
        "                else:\n",
        "                    model_name = \"gemini-pro\"\n",
        "                st.success(f\"Connected: {model_name}\")\n",
        "            except:\n",
        "                st.error(\"Invalid Key\")\n",
        "                model_name = None\n",
        "        else:\n",
        "            st.warning(\"Authentication Required\")\n",
        "            model_name = None\n",
        "\n",
        "        st.divider()\n",
        "        if st.button(\"üóëÔ∏è Clear Session\"):\n",
        "            st.session_state.messages = []\n",
        "            st.rerun()\n",
        "\n",
        "    # --- Main Chat Area ---\n",
        "    st.markdown(\"## ü©∫ Medi-RAG Interface\")\n",
        "\n",
        "    # Render History\n",
        "    for msg in st.session_state.messages:\n",
        "        with st.chat_message(msg[\"role\"]):\n",
        "            st.markdown(msg[\"content\"])\n",
        "\n",
        "    # Input Handler\n",
        "    if prompt := st.chat_input(\"Ask a medical question (e.g., Treatment for Typhoid)...\"):\n",
        "        # User Message\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        # AI Response\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            if not data_bundle:\n",
        "                st.error(\"üö® System Error: Corpus not loaded. Check Google Drive.\")\n",
        "            elif not api_key:\n",
        "                st.info(\"üîë Please authenticate with your API Key in the sidebar.\")\n",
        "            else:\n",
        "                # Unpack Data\n",
        "                df, tfidf, matrix, embedder, index = data_bundle\n",
        "\n",
        "                try:\n",
        "                    # 1. Search Logic\n",
        "                    stemmer = PorterStemmer()\n",
        "                    stop = set(stopwords.words(\"english\"))\n",
        "                    q_clean = \" \".join([stemmer.stem(w) for w in re.sub(r\"[^a-z0-9 ]\", \" \", prompt.lower()).split() if w not in stop])\n",
        "                    q_vec = tfidf.transform([q_clean])\n",
        "\n",
        "                    # Scoring\n",
        "                    scores = (matrix @ q_vec.T).toarray().ravel()\n",
        "                    top_idx = scores.argsort()[::-1][:8]\n",
        "                    results = df.iloc[top_idx].copy()\n",
        "\n",
        "                    # Add Scores to Results DataFrame\n",
        "                    results[\"relevance\"] = scores[top_idx]\n",
        "                    results = results[results[\"relevance\"] > 0.01] # Filter noise\n",
        "\n",
        "                    # Vector Search (Context)\n",
        "                    q_emb = embedder.encode([prompt]).astype(\"float32\")\n",
        "                    _, v_idx = index.search(q_emb, 3)\n",
        "\n",
        "                    context_text = \"\"\n",
        "                    for i in v_idx[0]:\n",
        "                        context_text += f\"\\nSOURCE: {df.iloc[i]['title']}\\n{df.iloc[i]['content'][:1500]}\\n\"\n",
        "\n",
        "                    # 2. Generation\n",
        "                    if model_name:\n",
        "                        llm = genai.GenerativeModel(model_name)\n",
        "                        sys_prompt = f\"\"\"You are an expert medical assistant. Use ONLY the provided sources to answer.\n",
        "                        Query: {prompt}\n",
        "                        Sources: {context_text}\n",
        "                        Format: Start with a direct answer/summary, then provide bulleted details. Mention source names.\"\"\"\n",
        "\n",
        "                        response_placeholder = st.empty()\n",
        "                        full_response = \"\"\n",
        "                        for chunk in llm.generate_content(sys_prompt, stream=True):\n",
        "                            full_response += chunk.text\n",
        "                            response_placeholder.markdown(full_response + \"‚ñå\")\n",
        "                        response_placeholder.markdown(full_response)\n",
        "\n",
        "                        st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})\n",
        "\n",
        "                    # 3. Analytics Panel (Exact Requirements)\n",
        "                    with st.expander(\"üìä Analytics Dashboard (Table & Graph)\", expanded=True):\n",
        "                        col_a, col_b = st.columns([1.5, 1])\n",
        "\n",
        "                        # Prepare DataFrame for Display\n",
        "                        # Renaming columns to match user request exactly\n",
        "                        display_df = results.copy()\n",
        "                        display_df = display_df.rename(columns={\n",
        "                            \"title\": \"Document\",\n",
        "                            \"relevance\": \"TF-IDF\",\n",
        "                            \"pagerank\": \"PageRank\",\n",
        "                            \"authority\": \"Authority\",\n",
        "                            \"cluster\": \"Cluster\"\n",
        "                        })\n",
        "\n",
        "                        # Select specific columns\n",
        "                        final_table = display_df[[\"Document\", \"TF-IDF\", \"PageRank\", \"Authority\", \"Cluster\"]]\n",
        "\n",
        "                        with col_a:\n",
        "                            # Graph\n",
        "                            if not results.empty:\n",
        "                                fig = px.scatter(\n",
        "                                    display_df,\n",
        "                                    x=\"PageRank\",\n",
        "                                    y=\"Authority\",\n",
        "                                    size=\"TF-IDF\",\n",
        "                                    color=\"Cluster\",\n",
        "                                    hover_name=\"Document\",\n",
        "                                    text=\"Document\",\n",
        "                                    title=\"Document Authority vs PageRank\",\n",
        "                                    template=\"plotly_dark\"\n",
        "                                )\n",
        "                                fig.update_traces(textposition='top center', marker=dict(line=dict(width=1, color='white')))\n",
        "                                fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
        "                                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "                        with col_b:\n",
        "                            # Table\n",
        "                            st.markdown(\"### Retrieval Metrics\")\n",
        "                            st.dataframe(\n",
        "                                final_table.style.background_gradient(subset=[\"TF-IDF\"], cmap=\"GnBu\"),\n",
        "                                hide_index=True,\n",
        "                                use_container_width=True\n",
        "                            )\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error: {e}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. ROUTER\n",
        "# ==========================================\n",
        "if st.session_state.page == \"landing\":\n",
        "    landing_page()\n",
        "else:\n",
        "    app_interface()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymcYEtnpgl5K",
        "outputId": "0f193cf3-f4d3-4c8f-cfcb-ea336a95b5c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: streamlit-lottie in /usr/local/lib/python3.12/dist-packages (0.0.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank-bm25, faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.0 rank-bm25-0.2.2\n",
            "‚è≥ Starting Streamlit Server...\n",
            "\n",
            "‚úÖ Your App is Live! Click below:\n",
            "üëâ https://hydrocarbonaceous-caitlyn-dressiest.ngrok-free.dev\n"
          ]
        }
      ],
      "source": [
        "# 1. Install Missing Libraries (Fixes ModuleNotFoundError)\n",
        "!pip install faiss-cpu streamlit pyngrok sentence-transformers google-generativeai rank-bm25 plotly streamlit-lottie scikit-learn\n",
        "\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# 2. Authenticate Ngrok\n",
        "# =====================================================\n",
        "ngrok_token = \"35m9eJCZMShYBqq1EI5P7p0DVQ4_6y2RQrPkN4RdxQxbqr2EW\"  # <--- PASTE TOKEN HERE\n",
        "# =====================================================\n",
        "\n",
        "if ngrok_token == \"PASTE_YOUR_TOKEN_HERE\":\n",
        "    print(\"‚ùå Error: You forgot to paste your Ngrok token!\")\n",
        "else:\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "    # 3. Kill old processes to free up memory\n",
        "    ngrok.kill()\n",
        "    os.system(\"pkill streamlit\")\n",
        "\n",
        "    # 4. Run Streamlit in the background\n",
        "    print(\"‚è≥ Starting Streamlit Server...\")\n",
        "    os.system(\"nohup streamlit run app.py --server.port 8501 &\")\n",
        "\n",
        "    # 5. Open the Connection\n",
        "    try:\n",
        "        # Open a tunnel to port 8501\n",
        "        public_url = ngrok.connect(8501).public_url\n",
        "        print(\"\\n‚úÖ Your App is Live! Click below:\")\n",
        "        print(f\"üëâ {public_url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Ngrok Error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}