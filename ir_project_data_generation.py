# -*- coding: utf-8 -*-
"""IR project data generation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Thgs6zJYtMOSqcjffVkh5HgkRMh1PqXR
"""

# Cell 1: Install the library (Shell Command)
!pip install wikipedia

# Cell 2: Import the library (Python Code)
import wikipedia
import os
import re

# You can now proceed with your data generation script
# ...

import wikipedia
import os
import re

# --- Configuration ---
DISEASE_LIST = [
    # **Infectious Diseases (Viruses, Bacteria, Fungi, Parasites)**
    "Malaria", "Tuberculosis", "Influenza", "HIV/AIDS", "COVID-19",
    "Measles", "Mumps", "Rubella", "Varicella", "Shingles (Herpes Zoster)",
    "Hepatitis A", "Hepatitis B", "Hepatitis C", "Typhoid fever", "Cholera",
    "Pneumonia", "Meningitis", "Sepsis", "Ebola virus disease", "Dengue fever",
    "Zika fever", "Lyme disease", "Rabies", "Tetanus", "Polio",
    "Syphilis", "Gonorrhea", "Chlamydia", "Herpes simplex", "E. coli infection",
    "Salmonella", "Ringworm", "Candidiasis", "Histoplasmosis", "Botulism",

    # **Chronic & Non-Communicable Diseases**
    "Diabetes mellitus type 1", "Diabetes mellitus type 2", "Hypertension",
    "Coronary heart disease", "Stroke", "Heart failure", "Chronic kidney disease",
    "Chronic obstructive pulmonary disease (COPD)", "Asthma", "Allergic rhinitis",
    "Irritable bowel syndrome (IBS)", "Crohn's disease", "Ulcerative colitis",
    "Celiac disease", "Gout", "Osteoarthritis", "Rheumatoid arthritis",
    "Lupus erythematosus", "Multiple sclerosis (MS)", "Fibromyalgia", "Cystic fibrosis",
    "Obesity", "Cirrhosis", "Non-alcoholic fatty liver disease (NAFLD)", "Psoriasis",

    # **Neuropsychiatric and Neurological Disorders**
    "Alzheimer's disease", "Parkinson's disease", "Schizophrenia",
    "Bipolar disorder", "Major depressive disorder", "Anxiety disorder",
    "Obsessive-compulsive disorder (OCD)", "Autism spectrum disorder",
    "Attention deficit hyperactivity disorder (ADHD)", "Epilepsy",
    "Migraine", "Tourette syndrome", "Amyotrophic lateral sclerosis (ALS)",
    "Huntington's disease", "Guillain-Barré syndrome", "Restless legs syndrome",
    "Narcolepsy", "Spinal muscular atrophy (SMA)", "Meningitis", "Concussion",

    # **Cancers (Oncology)**
    "Breast cancer", "Lung cancer", "Prostate cancer", "Colorectal cancer",
    "Ovarian cancer", "Pancreatic cancer", "Leukemia", "Lymphoma (Non-Hodgkin)",
    "Thyroid cancer", "Skin cancer (Melanoma)", "Brain tumor (Glioblastoma)",
    "Sarcoma", "Multiple myeloma", "Esophageal cancer", "Bladder cancer",

    # **Endocrine and Metabolic Disorders**
    "Hypothyroidism", "Hyperthyroidism (Graves' disease)", "Addison's disease",
    "Cushing's syndrome", "Polycystic ovary syndrome (PCOS)", "Osteoporosis",
    "Hemochromatosis", "Phenylketonuria (PKU)", "Galactosemia",

    # **Genetic and Developmental Disorders**
    "Down syndrome", "Turner syndrome", "Fragile X syndrome", "Muscular dystrophy",
    "Sickle cell disease", "Thalassemia", "Hemophilia", "Marfan syndrome",
    "Ehlers-Danlos syndrome", "Tay-Sachs disease", "Spina bifida",

    # **Miscellaneous Conditions**
    "Anemia", "Glaucoma", "Cataracts", "Sleep apnea", "Tinnitus",
    "Eczema (Atopic dermatitis)", "Allergies (Anaphylaxis)", "Deep vein thrombosis (DVT)",
    "Peptic ulcer disease", "Gastroesophageal reflux disease (GERD)",
    "Cataracts", "Diverticulitis", "Fibroids", "Endometriosis",
    "Sleep apnea", "Scoliosis", "Bursitis", "Pneumothorax", "Appendicitis",
    "Cellulitis", "Scurvy", "Rickets", "Kawasaki disease", "Plantar fasciitis",
    "Tonsillitis", "Pleurisy", "Vertigo", "Pneumoconiosis", "Yellow fever",
    "Hansen's disease (Leprosy)", "Sjögren's syndrome", "Vitiligo",
    "Alopecia areata", "Bells palsy", "Laryngitis", "Pericarditis", "Retinoblastoma",
    "Urticaria (Hives)", "Raynaud's phenomenon", "Sarcoidosis", "Hashimoto's thyroiditis",
    "Myasthenia gravis", "Cerebral palsy", "Hydrocephalus", "Toxoplasmosis",
    "Ectopic pregnancy", "Pre-eclampsia", "Endocarditis", "Aphasia", "Dyslexia"
]
OUTPUT_DIR = "wikipedia_medical_corpus"

def clean_wiki_content(text):
    """
    Cleans the raw Wikipedia page content for better use in RAG/IR.
    - Removes common Wikipedia section headers (e.g., '== See also ==').
    - Removes excessive newlines.
    """
    # 1. Remove section headers like '== References ==', '== See also ==', etc.
    text = re.sub(r'={2,}\s*[^=]+\s*={2,}', '', text)
    # 2. Remove text within parentheses (often citations or alternative names)
    text = re.sub(r'\([^()]*\)', '', text)
    # 3. Clean up excessive whitespace and newlines
    text = re.sub(r'\n{2,}', '\n\n', text)
    return text.strip()

def fetch_and_save_page(title, output_dir):
    """Fetches Wikipedia content and saves it as a clean text file."""

    # Standardize the filename
    safe_title = title.replace(' ', '_').replace('/', '_')
    file_path = os.path.join(output_dir, f"{safe_title}.txt")

    # Check if file already exists to avoid repeated API calls
    if os.path.exists(file_path):
        print(f"Skipping: {title} (Already exists)")
        return

    try:
        # 1. Fetch the full page content
        # Note: The 'wikipedia' library automatically returns plain text.
        page = wikipedia.page(title, auto_suggest=False)
        raw_content = page.content

        # 2. Clean the content
        cleaned_content = clean_wiki_content(raw_content)

        # 3. Save to file
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"# {title}\n\n") # Add a title header
            f.write(cleaned_content)

        print(f"SUCCESS: Saved content for '{title}' to {file_path}")

    except wikipedia.exceptions.PageError:
        print(f"FAIL: Wikipedia page not found for '{title}'")
    except wikipedia.exceptions.DisambiguationError as e:
        # Handles cases where the search term leads to multiple options
        print(f"FAIL: Disambiguation for '{title}'. Options: {e.options[:5]}")
        # You can choose to automatically select the first option:
        # fetch_and_save_page(e.options[0], output_dir)
    except Exception as e:
        print(f"ERROR processing '{title}': {e}")


if __name__ == "__main__":
    # Create the output directory if it doesn't exist
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # Set the language to English (default, but good practice)
    wikipedia.set_lang("en")

    print(f"Starting to download {len(DISEASE_LIST)} pages...")

    # Iterate through your list of diseases
    for disease in DISEASE_LIST:
        fetch_and_save_page(disease, OUTPUT_DIR)

    print("\nData generation complete.")

# Assuming your directory is named 'wikipedia_medical_corpus'
!ls wikipedia_medical_corpus | grep '.txt' | wc -l

import wikipedia
import os
import re
import time

# --- Configuration ---
# NOTE: This list contains 60 common diseases to expand your corpus.
DISEASE_LIST_COMMON = [
    # Cardiovascular and Metabolic
    "Ischemic heart disease", "Atherosclerosis", "Myocardial infarction",
    "Congestive heart failure", "Aortic stenosis", "Peripheral Artery Disease",
    "Hypertensive heart disease", "Hyperlipidemia", "Obesity", "Metabolic syndrome",

    # Respiratory System Diseases
    "Chronic Bronchitis", "Emphysema", "Acute Bronchitis", "Pharyngitis",
    "Laryngitis", "Sinusitis", "Sleep apnea", "Tonsillitis", "Pneumonia",
    "Tuberculosis", # Kept for commonality (even if in base list)

    # Common Infectious Diseases
    "Common cold", "Gastroenteritis", "Urinary tract infection", "Strep throat",
    "Mononucleosis", "Cellulitis", "Impetigo", "Conjunctivitis",
    "Rotavirus infection", "Human papillomavirus",

    # Musculoskeletal and Joint Disorders
    "Osteoarthritis", "Rheumatoid arthritis", "Gout", "Bursitis",
    "Tendonitis", "Carpal tunnel syndrome", "Scoliosis", "Chronic low back pain",

    # Mental Health and Neurological Conditions
    "Major Depressive Disorder", "Generalized Anxiety Disorder", "Bipolar disorder",
    "Attention-Deficit/Hyperactivity Disorder", "Migraine", "Tension headache",
    "Insomnia",

    # Gastrointestinal and Digestive Disorders
    "Gastroesophageal Reflux Disease", "Irritable Bowel Syndrome",
    "Peptic ulcer disease", "Gallstones", "Hemorrhoids", "Appendicitis",
    "Diverticulitis", # Added for uniqueness

    # Skin (Dermatological) Conditions
    "Acne vulgaris", "Psoriasis", "Ringworm", "Warts",

    # Ear, Eye, and Other Common Conditions
    "Otitis media", "Cataract", "Glaucoma", "Allergies"
]
OUTPUT_DIR = "wikipedia_medical_corpus" # Use the same directory name

def clean_wiki_content(text):
    """
    Cleans the raw Wikipedia page content by removing common section headers
    and excessive newlines, making it suitable for IR indexing.
    """
    # Remove all sections starting with two equals signs (== References ==)
    text = re.sub(r'={2,}\s*[^=]+\s*={2,}', '', text)
    # Remove content within parentheses (often citations, scientific names)
    text = re.sub(r'\([^()]*\)', '', text)
    # Clean up excessive whitespace and newlines
    text = re.sub(r'\n{2,}', '\n\n', text)
    return text.strip()

def fetch_and_save_page(title, output_dir, file_counter):
    """Fetches Wikipedia content and saves it as a clean text file."""

    # Standardize the filename
    safe_title = title.replace(' ', '_').replace('/', '_').replace("'", "")

    # Create a unique filename using a counter for easy tracking
    file_path = os.path.join(output_dir, f"DOC_COMMON_{file_counter:03d}_{safe_title}.txt")

    if os.path.exists(file_path):
        print(f"Skipping: {title} (File exists: {file_path})")
        return file_counter # Return existing counter

    try:
        # Fetch the full page content
        page = wikipedia.page(title, auto_suggest=False)
        raw_content = page.content

        # Clean the content
        cleaned_content = clean_wiki_content(raw_content)

        # Save to file
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"# DISEASE: {title}\n\n") # Add a descriptive header
            f.write(cleaned_content)

        print(f"SUCCESS [{file_counter:03d}]: Saved '{title}'")
        return file_counter + 1

    except wikipedia.exceptions.PageError:
        print(f"FAIL: Wikipedia page not found for '{title}'")
        return file_counter
    except wikipedia.exceptions.DisambiguationError as e:
        print(f"FAIL: Disambiguation for '{title}'. Attempting first option: {e.options[0]}")
        # Try fetching the first suggested option to maximize data retrieval
        try:
            page = wikipedia.page(e.options[0], auto_suggest=False)
            cleaned_content = clean_wiki_content(page.content)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"# DISEASE: {title} (Disambiguated to {e.options[0]})\n\n")
                f.write(cleaned_content)
            print(f"SUCCESS (Disambiguated): Saved '{title}' via '{e.options[0]}'")
            return file_counter + 1
        except Exception:
            print(f"FAIL: Could not resolve disambiguation for '{title}'.")
            return file_counter
    except Exception as e:
        print(f"ERROR processing '{title}': {e}")
        return file_counter


if __name__ == "__main__":
    # Create the output directory if it doesn't exist
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # Set the language to English (default)
    wikipedia.set_lang("en")

    print(f"Starting download of {len(DISEASE_LIST_COMMON)} COMMON disease pages...")

    # Initialize file counter based on the number of pages we plan to add
    file_counter = 1

    # Iterate and fetch
    for disease in DISEASE_LIST_COMMON:
        file_counter = fetch_and_save_page(disease, OUTPUT_DIR, file_counter)
        # Introduce a small delay to avoid hitting Wikipedia API rate limits
        time.sleep(0.5)

    print("\nData generation for COMMON diseases complete.")
    print(f"Final count of newly processed unique files: {file_counter - 1}")

    # Final verification of ALL files in the corpus directory:
    total_files = sum(1 for item in os.listdir(OUTPUT_DIR) if item.endswith(".txt"))
    print(f"*** TOTAL FILES NOW IN CORPUS: {total_files} ***")

# Create a zip file of the entire corpus folder
!zip -r corpus_archive.zip wikipedia_medical_corpus/

from google.colab import files
files.download('corpus_archive.zip')